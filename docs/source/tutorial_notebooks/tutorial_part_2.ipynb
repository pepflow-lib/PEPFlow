{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c817e130-0253-4630-b8e7-7b40fc19bfa3",
   "metadata": {},
   "source": [
    "<a id=\"sec-proof\"></a>\n",
    "# Deriving analytical proofs <span class=\"toc-short\" data-short-title=\"Analytical proofs\"></span>\n",
    "\n",
    "PEP and <span class=\"brand-color\">PEPFlow</span> go far beyond merely numerical verification. From the dual variables (Lagrange multipliers) of Primal PEP, one can extract rigorous convergence proofs. <span class=\"brand-color\">PEPFlow</span> bridges theory and practice by giving direct access to these dual variables and by offering an interactive environment for developing and verifying analytical proofs.\n",
    "\n",
    "In this section, we consider a simpler running example: $N=2$ iterations of GD.  The following code block creates the PEPContext and builds the $2$-step GD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c028c416-22de-4974-9267-26b0cccbb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pepflow as pf\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import itertools\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee3d5b2a-ed93-454b-845b-30d9700566a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xjiang/Documents/GitHub/pepflow-lib/pepflow/pep_context.py:171: UserWarning:\n",
      "\n",
      "The provided name was already used. The older PEPContext will be overwritten. PEPBuilders constructed with the older PEPContext should be remade.\n",
      "\n",
      "/Users/xjiang/Documents/GitHub/pepflow-lib/pepflow/function.py:158: UserWarning:\n",
      "\n",
      "Warning: function or operator with tag f has been created before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L = pf.Parameter(\"L\")\n",
    "R = pf.Parameter(\"R\")\n",
    "N = sp.S(2)\n",
    "alpha = 1 / L\n",
    "\n",
    "ctx = pf.PEPContext(\"gd\").set_as_current()\n",
    "pep_builder = pf.PEPBuilder(ctx)\n",
    "\n",
    "# Define function class\n",
    "f = pf.SmoothConvexFunction(is_basis=True, tags=[\"f\"], L=L)\n",
    "x_star = f.set_stationary_point(\"x_star\")\n",
    "\n",
    "# Set the initial condition\n",
    "x = pf.Vector(is_basis=True, tags=[\"x_0\"])  # The first iterate\n",
    "pep_builder.add_initial_constraint(\n",
    "    ((x - x_star) ** 2).le(R**2, name=\"initial_condition\")\n",
    ")\n",
    "\n",
    "# Define the gradient descent method\n",
    "for i in range(N):\n",
    "    x = x - alpha * f.grad(x)\n",
    "    x.add_tag(f\"x_{i + 1}\")\n",
    "\n",
    "# Set the performance metric\n",
    "x_N = ctx[f\"x_{N}\"]\n",
    "pep_builder.set_performance_metric(f(x_N) - f(x_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861fe95-4bf7-4a3b-8b65-b913e201518c",
   "metadata": {},
   "source": [
    "Before exploring the advanced features of <span class=\"brand-color\">PEPFlow</span>, we first need to understand the theory behind PEP, in particular how convergence proofs can be derived through duality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff070eb0-da8e-4373-95ce-e1276b045f50",
   "metadata": {},
   "source": [
    "## PEP theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6470da1-7afb-47bd-90b4-adb95cb78d7e",
   "metadata": {},
   "source": [
    "### From [PEP](tutorial_part_1.ipynb#verifying-numerical-rates-of-convergence) to QCQP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0bc98d-18bc-4f0d-a08b-0bf2d930cf96",
   "metadata": {},
   "source": [
    "The [PEP](tutorial_part_1.ipynb#verifying-numerical-rates-of-convergence) problem captures the spirit of a performance estimation problem: we search over all $L$-smooth convex functions and all GD iterates to find the scenario that maximizes the final objective gap. To make this problem tractable for computation, we need to express it entirely in terms of numerical quantities---iterates, function values, and gradient values---rather than abstract function classes. The last three sets of constraints in {eq}`eq:pep` are relatively straightforward to handle; the main difficulty lies in enforcing that $f$ is $L$-smooth convex.\n",
    "\n",
    "For $L$-smooth convex functions, the defining inequalities between function values, gradients, and points are well known: \n",
    "```{math}\n",
    "f(x) - f(y) + \\langle \\nabla f(x), y-x\\rangle + \\tfrac{1}{L} \\|\\nabla f(x) - \\nabla f(y)\\|^2 \\leq 0 \\quad \\text{for all} \\ x, y \\in \\mathbf{dom} \\, f.\n",
    "```\n",
    "This __infinite__ collection of constraints is still intractable, as no numerical solver can handle all possible pairs $(x,y)$ in the domain of $f$. However, the points of our interest are only those visited by the algorithm, together with the convergent optimum $x_\\star$. It is therefore natural to __relax__ the above infinite family into a __finite__ one:\n",
    "```{math}\n",
    "f(x_j) - f(x_i) + \\langle \\nabla f(x_j), x_i - x_j \\rangle + \\tfrac{1}{L} \\|\\nabla f(x_i) - \\nabla f(x_j)\\|^2 \\leq 0 \\quad \\text{for all} \\ (x_i, x_j) \\in \\mathcal{K}^\\star_N,\n",
    "```\n",
    "where the index sets $\\mathcal K^\\star_N$ are defined as\n",
    "```{math}\n",
    ":label: eq:index\n",
    "\n",
    "\\mathcal{I}^\\star_N := \\{0,1,2,\\ldots,N,\\star\\}, \\qquad \\mathcal{K}^\\star_N := \\{(i,j) \\mid i \\in \\mathcal{I}^\\star_N, j \\in \\mathcal{I}^\\star_N, i \\neq j\\}.\n",
    "```\n",
    "Remarkably, this relaxation turns out to be __exact__: the worst-case behavior of $L$-smooth convex functions is fully captured by these finitely many points [^2]. As a result, [the original problem](tutorial_part_1.ipynb#verifying-numerical-rates-of-convergence) can be formulated equivalently as a nonconvex quadratically constrained quadratic program (QCQP):\n",
    "```{math}\n",
    ":label: eq:pep-qcqp\n",
    "\n",
    "\\begin{array}{ll}\n",
    "    \\text{maximize} & f_N - f_\\star \\\\\n",
    "    \\text{subject to} & f_j - f_i + \\langle g_j, x_i - x_j \\rangle + \\tfrac{1}{L} \\|g_i - g_j\\|^2 \\leq 0, \\;\\; (i,j) \\in \\mathcal{K}^\\star_N \\\\\n",
    "    & x_j = x_0 - \\alpha \\sum_{i=0}^{j-1} g_i, \\;\\; j=1,2,\\ldots,N \\\\\n",
    "    & \\|x_0 - x_\\star\\|^2 \\leq R^2 \\\\\n",
    "    & g_\\star = 0,\n",
    "\\end{array}\n",
    "```\n",
    "where the optimization variables are $\\{(x_i, f_i, g_i)\\}_{i \\in \\mathcal{I}^\\star_N}$; recall that the index sets $\\mathcal{I}^\\star_N$ and $\\mathcal{K}^\\star_N$ are defined in {eq}`eq:index`.\n",
    "(One can view $f_i$ as $f(x_i)$ and $g_i$ as $\\nabla f(x_i)$.)\n",
    "\n",
    "Moreover, the __independent__ or <span class=\"brand-color\">basis variables</span> in {eq}`eq:pep-qcqp` are\n",
    "```{math}\n",
    ":label: eq:var\n",
    "\n",
    "\\digamma := (f_\\star, f_0, f_1, \\ldots, f_N) \\in \\mathbb R^{N+2}, \\qquad \\quad H := \\begin{bmatrix} x_\\star & x_0 & g_0 & g_1 & \\cdots & g_N \\end{bmatrix} \\in \\mathbb R^{d \\times (N+3)}.\n",
    "```\n",
    "More specifically, entries in $\\digamma$, $f_i$ for $i \\in \\mathcal I_N^\\star$, are called <span class=\"brand-color\">basis scalars</span> and columns of $H$ are called <span class=\"brand-color\">basis vectors</span>.\n",
    "On the other hand, the variables $\\{x_1,\\ldots,x_N\\}$ are called <span class=\"brand-color\">non-basis variables</span> as they are linear combinations of columns of $H$. So, the second set of constraints in {eq}`eq:pep-qcqp` describing the algorithm update rule can be removed. The <span class=\"brand-color\">non-basis variables</span> $x_1, x_2, \\ldots, x_N$ can then be substituted directly into the first group of constraints, leaving a reduced formulation expressed entirely in terms of $\\digamma$ and $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41035b-b7ca-4359-a1d2-a96c3d20491d",
   "metadata": {},
   "source": [
    "<span class=\"brand-color\">Basis variables</span> __in__ <span class=\"brand-color\">PEPFlow</span>.\n",
    "In <span class=\"brand-color\">PEPFlow</span>, the elements of the decision variable $\\digamma$ are stored as `Scalar` objects, or `EvaluatedScalar` objects, if they are evaluated. Using <span class=\"brand-color\">PEPFlow</span> we can easily see the basis scalars that a `PEPContext` is managing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c00150da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[f(x_star), f(x_0), f(x_1), f(x_2)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.basis_scalars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ca8b3-e73a-4414-be58-538ecb2969be",
   "metadata": {},
   "source": [
    "To see the coordinates of a `Scalar` object, we will create an `ExpressionManager` object which evaluates `Scalar` objects and returns an `EvaluatedScalar` object. Let us find the `EvaluatedScalar` object associated with the `Scalar` object representing `f(x_0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33d2e15d-c0d7-458f-9ba1-c6cfe1560177",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = ctx[\"x_0\"]\n",
    "pm = pf.ExpressionManager(ctx, resolve_parameters={\"L\": sp.S(1)})\n",
    "eval_sc_example = pm.eval_scalar(f(x_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345e77d-1a8f-4537-a035-875d0bd472f5",
   "metadata": {},
   "source": [
    "The `EvaluatedScalar` object stores the information about the `Scalar` object's coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d39981f-1858-4bf5-bc77-18a07bd7ba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{cccc}\n",
       "        f(x_\\star) & f(x_0) & f(x_1) & f(x_2) \\\\\n",
       "        \\hline\n",
       "        0.0 & 1.0 & 0.0 & 0.0\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf.pprint_labeled_vector(eval_sc_example.func_coords, ctx.basis_scalars_math_exprs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ae9ee-42e1-4de7-a030-88255844b079",
   "metadata": {},
   "source": [
    "This line of code simply means that the _coordinate_ of $f_0$ is $(0,1,0,0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd89b4-cb06-4ea8-890b-48151173461c",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "The <span class=\"brand-color\">mathematical expression</span> and <span class=\"brand-color\">coordinate</span> systems in <span class=\"brand-color\">PEPFlow</span> ensure that all user inputs are represented by a mathematical expression, while all computations are carried out in coordinates automatically.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532d8b4-1396-4790-a156-8e3762a4236f",
   "metadata": {},
   "source": [
    "```{admonition} Mathematical Expressions of Basis Scalars and Basis Vectors\n",
    ":class: dropdown pepflow-dropdown\n",
    "\n",
    "All `Vector` and `Scalar` objects have an underlying mathematical expression. The mathematical expressions of basis `Vector` and `Scalar` objects come from the last tag given to the object by the user. For `Vector` and `Scalar` objects formed by linear combinations of basis objects, the mathematical expression comes from the last tag given to the object by the user or, if the user did not provide any tag for the composite object, will be automatically generated from the mathematical expressions of basis objects. \n",
    "\n",
    "The mathematical expressions of all basis scalars managed by a `PEPContext` `ctx` can be found through `ctx.basis_scalars_math_exprs()`. Similarly, the mathematical expressions of all basis vectors managed by a `PEPContext` `ctx` can be found through `ctx.basis_vectors_math_exprs()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c76dc-c052-44d4-9cf3-cb19a281cfa6",
   "metadata": {},
   "source": [
    "```{admonition} Retrieving $H$ in PEPFlow\n",
    ":class: dropdown pepflow-dropdown\n",
    "\n",
    "A similar argument can be made for the elements of $H$, which are stored in <span class=\"brand-color\">PEPFlow</span> as `Vector` (or `EvaluatedVector`) objects. The following code prints the <span class=\"brand-color\">basic vectors</span> and the coordinate of, _e.g._, $x_2$.\n",
    "\n",
    "```python\n",
    "ctx.basis_vectors()\n",
    "pm.eval_vector(ctx[\"x_2\"]).coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487211d0-dcc4-431c-b567-c68a577a4da2",
   "metadata": {},
   "source": [
    "### From QCQP to SDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0fa6e-d703-48ff-a233-7917ed9e45de",
   "metadata": {},
   "source": [
    "It is now straightforward to transform the nonconvex QCQP {eq}`eq:pep-qcqp` into a semidefinite program (SDP), which is a convex optimization problem. To do so, we introduce the Gram matrix associated with $H$:\n",
    "\n",
    "```{math}\n",
    "G := H^T H = \\begin{bmatrix}\n",
    "    \\langle x_\\star, x_\\star \\rangle & \\langle x_\\star, x_0 \\rangle & \\langle x_\\star, g_0 \\rangle & \\langle x_\\star, g_1 \\rangle & \\cdots & \\langle x_\\star, g_N \\rangle \\\\\n",
    "    \\langle x_0, x_\\star \\rangle & \\ddots & & & & \\vdots \\\\\n",
    "    \\langle g_0, x_\\star \\rangle & & \\ddots & & & \\vdots \\\\\n",
    "    \\vdots & & & & & \\vdots \\\\\n",
    "    \\langle g_N, x_\\star \\rangle & \\cdots & \\cdots & \\cdots & \\cdots & \\langle g_N, g_N \\rangle\n",
    "\\end{bmatrix} \\in \\mathbb S^{N+3}.\n",
    "```\n",
    "\n",
    "With this definition, every term in {eq}`eq:pep-qcqp` becomes linear in $\\digamma$ and $G$. For instance, the objective depends linearly on $\\digamma$, and inner-product terms such as $\\langle g_j, x_i \\rangle$ can be expressed as $\\langle G, E \\rangle$ for some coefficient matrix $E$. Under mild conditions (_e.g._, $d \\geq N+3$ [^1]), the QCQP {eq}`eq:pep-qcqp` can be equivalently reformulated as the so-called __Primal PEP__:\n",
    "```{math}\n",
    ":label: eq:pep-sdp\n",
    "\n",
    "\\begin{array}{lll}\n",
    "    \\text{minimize} & \\langle \\digamma, c^{\\text{PM}} \\rangle + \\langle G, C^{\\text{PM}} \\rangle \\\\\n",
    "    \\text{subject to} & \\langle \\digamma, c^{\\text{FC}}_{ij} \\rangle + \\langle G, C^{\\text{FC}}_{ij} \\rangle \\leq 0, \\;\\; (i,j) \\in \\mathcal{K}^\\star_N \\\\\n",
    "    & \\langle \\digamma, c^{\\text{IC}} \\rangle + \\langle G, C^{\\text{IC}} \\rangle - R^2 \\leq 0 \\\\\n",
    "    & G \\succeq 0\n",
    "\\end{array}\n",
    "```\n",
    "with variables $\\digamma \\in \\mathbb{R}^{N+2}$ and $G \\in \\mathbb{S}^{N+3}$. The notation $G \\succeq 0$ means that $G$ is symmetric positive semidefinite. Here, $(c^\\text{PM}, C^\\text{PM})$ correspond to the performance metric, $\\{(c^\\text{FC}_{ij}, C^\\text{FC}_{ij})\\}$ to the function class, and $(c^\\text{IC}, C^\\text{IC})$ to the initial condition. We omit the explicit expressions, because <span class=\"brand-color\">PEPFlow</span> constructs them automatically and makes them easily accessible. For example, to obtain the coefficient matrix $E$ satisfying $\\langle G, E\\rangle = \\langle g_1, x_0 \\rangle$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d655baa8-c286-41df-9a48-cbeb9476bf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = ctx[\"x_1\"]\n",
    "g_1 = f.grad(x_1)\n",
    "pm.eval_scalar(g_1 * x_0).inner_prod_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1d427-b9a2-4ca1-8f81-1905c02d66c1",
   "metadata": {},
   "source": [
    "We are now ready to show how convergence proofs arise from duality theory. Let $\\lambda_{ij} \\in \\mathbb{R}$ denote the Lagrange multipliers associated with the functional constraints, $\\tau \\in \\mathbb{R}$ with the initial condition, and $S \\in \\mathbb{S}^{N+3}$ with the PSD constraint in {eq}`eq:pep-sdp`. Then the corresponding Lagrangian is\n",
    "\n",
    "```{math}\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathcal{L} (\\digamma, G; \\{\\lambda_{ij}\\}_{(i,j) \\in \\mathcal{K}^\\star_N}, \\tau, S) \\\\\n",
    "\\overset{(\\blacktriangle)}{=} &\\ \\langle \\digamma, c^\\text{PM} \\rangle + \\langle G, C^\\text{PM} \\rangle\n",
    "- \\sum_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} (\\langle \\digamma, c^\\text{FC}_{ij} \\rangle + \\langle G, C^\\text{FC}_{ij} \\rangle)\n",
    "- \\tau (\\langle \\digamma, c^\\text{IC} \\rangle + \\langle G, C^\\text{IC} \\rangle - R^2)\n",
    "+ \\langle G, S \\rangle \\\\\n",
    "\\overset{(\\blacktriangledown)}{=} &\\ \\tau R^2 + \\Big\\langle \\digamma, c^\\text{PM} - \\tau c^\\text{IC} - \\sum_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} c^\\text{FC}_{ij} \\Big\\rangle \n",
    "+ \\Big\\langle G, C^\\text{PM} - \\tau C^\\text{IC} - \\sum_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} C^\\text{FC}_{ij} + S \\Big\\rangle.\n",
    "\\end{align}\n",
    "```\n",
    "\n",
    "Hence, the dual of {eq}`eq:pep-sdp` is\n",
    "\n",
    "```{math}\n",
    ":label: eq:pep-sdp-dual \n",
    "\n",
    "\\begin{array}{ll} \n",
    "    \\text{minimize} & \\tau R^2 \\\\\n",
    "    \\text{subject to} & c^\\text{PM} - \\tau c^\\text{IC} - \\sum\\limits_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} c^\\text{FC}_{ij} = 0 \\\\\n",
    "    & C^\\text{PM} - \\tau C^\\text{IC} - \\sum\\limits_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} C^\\text{FC}_{ij} + S = 0 \\\\\n",
    "    & \\lambda_{ij} \\geq 0, \\;\\; (i,j) \\in \\mathcal{K}^\\star_N \\\\\n",
    "    & S \\succeq 0\n",
    "\\end{array}\n",
    "\n",
    "```\n",
    "with variables $\\{\\lambda_{ij}\\}_{(i,j) \\subset \\mathcal{K}^\\star_N} \\in \\mathbb{R}$, $\\tau \\in \\mathbb{R}$, and $S \\in \\mathbb{S}^{N+3}$.\n",
    "\n",
    "Given any primal feasible $(\\digamma, G)$ and dual feasible $(\\lambda, \\tau, S)$, the two inner-product terms on the right-hand side of ($\\blacktriangledown$) are both zero and then $\\mathcal{L} = \\tau R^2$. Substituting $\\mathcal{L} = \\tau R^2$ back to ($\\blacktriangle$) and reorganizing gives the identity\n",
    "\n",
    "```{math}\n",
    "\n",
    "\\begin{align}\n",
    "\\underbrace{\\langle \\digamma, c^\\text{PM} \\rangle + \\langle G, C^\\text{PM} \\rangle}_{\\text{performance metric}}\n",
    "- \\tau \\underbrace{\\big(\\langle \\digamma, c^\\text{IC} \\rangle + \\langle G, C^\\text{IC} \\rangle \\big)}_{\\text{initial condition}} \n",
    "&\\overset{(\\blacksquare)}{=} \\ \\sum_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} \\underbrace{\\big( \\langle \\digamma, c^\\text{FC}_{ij} \\rangle + \\langle G, C^\\text{FC}_{ij} \\rangle \\big)}_{\\text{functional constraints}} - \\underbrace{\\langle G, S \\rangle}_{\\text{sum of squares}} \\\\\n",
    "&\\leq 0.\n",
    "\\end{align}\n",
    "\n",
    "```\n",
    "The inequality follows directly from primal and dual feasibility.\n",
    "The last inner product $\\langle G, S \\rangle$ can be decomposed as sums of squares because $G = H^TH$ is a Gram matrix---we will revisit this point later.\n",
    "(The derivation of ($\\blacksquare$) is adapted from [^3], with minor modifications.)\n",
    "\n",
    "For our GD example, one can check that the equality ($\\blacksquare$) is exactly\n",
    "\n",
    "```{math}\n",
    ":label: eq:gd-prf\n",
    "\n",
    "f_N - f_\\star - {\\tau} \\| x_0 - x_\\star \\|^2_2 = \\sum_{(i,j) \\in {\\mathcal K}^\\star_N} {\\lambda}_{ij} \\Big(f_j - f_i + \\langle g_j, x_i - x_j \\rangle + \\tfrac{1}{2L} \\| g_i - g_j \\|^2_2 \\Big) - \\langle G, S \\rangle \\leq 0.\n",
    "```\n",
    "\n",
    "The inequality shows that the performance metric is upper bounded by a constant multiple of the initial distance, exactly the convergence guarantee we aim to establish.\n",
    "In short,\n",
    "<!-- <span style=\"color:red; font-weight:bold;\">In this way, a convergence guarantee is obtained by forming a weighted sum of all functional constraints, where the weights correspond to a dual feasible $\\lambda$, together with a sum-of-squares (SOS) term ensuring nonnegativity.</span> -->\n",
    "<p style=\"text-align:center; font-weight:bold; color:red;\">\n",
    "a convergence guarantee is obtained via a weighted sum of all functional constraints plus a sum-of-squares term.\n",
    "</p>\n",
    "\n",
    "Hence, proving convergence reduces to verifying the equality ($\\blacksquare$), a process known as the <span style=\"color:red; font-weight:bold;\">PEP-style proof</span>.\n",
    "A PEP-style proof consists of two steps:\n",
    "\n",
    "- __Step 1 dual weight identification:__ derive a symbolic expression for the dual variables $\\lambda_{ij}$, $(i,j) \\in \\mathcal{K}^\\star_N$.\n",
    "\n",
    "- __Step 2 Sum-of-squares (SOS) verification:__ confirm $S$ is PSD, or equivalently, decompose $\\langle G, S \\rangle$ into a sum of squares.\n",
    "\n",
    "Remarkably, the equality ($\\blacksquare$) holds for any primal feasible $(\\digamma, G)$ and dual feasible $(\\lambda, \\tau, S)$.\n",
    "The tightest bound corresponds to the minimal value of $\\tau$ (or equivalently, $\\tau R^2$), which is precisely the dual objective.\n",
    "Thus, a pair of primal and dual optimal points yields the __tight__ convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e5a1e-ac91-48f4-b54f-ea3016954d36",
   "metadata": {},
   "source": [
    "## Step 1 dual weight identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e351853-402a-4fe7-b0c8-86575b22df19",
   "metadata": {},
   "source": [
    "### Visualizing dual variables\n",
    "\n",
    "In <span class=\"brand-color\">PEPFlow</span>, we can visualize the dual solution $\\lambda$ as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f77c6d71-fd06-456c-8174-2a83474b0616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|cccc}\n",
       "         & x_0 & x_1 & x_2 & x_\\star \\\\\n",
       "        \\hline\n",
       "        x_0 & 0.0 & 0.106 & 0.169 & 0.0 \\\\x_1 & 0.029 & 0.0 & 0.493 & 0.0 \\\\x_2 & 0.006 & 0.072 & 0.0 & 0.0 \\\\x_\\star & 0.24 & 0.345 & 0.415 & 0.0 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pep_builder.solve(resolve_parameters={\"L\": sp.S(1), \"R\": sp.S(1)})\n",
    "lamb_dense = result.get_scalar_constraint_dual_value_in_numpy(f)\n",
    "lamb_dense.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9ee2f-4f5e-48b8-8ee1-3d6d06afaf90",
   "metadata": {},
   "source": [
    "```{admonition} Return type of result.get_scalar_constraint_dual_value_in_numpy(f)\n",
    ":class: dropdown pepflow-dropdown\n",
    "\n",
    "The code line `result.get_scalar_constraint_dual_value_in_numpy(f)` returns a `MatrixWithNames` object with the three member variables:\n",
    "- `matrix`: A `np.ndarray` containing the matrix of the dual values associated with the interpolation constraints of `f`;\n",
    "- `row_names`: A list of strings containing the math expressions of the points visited by `f`;\n",
    "- `col_names`: A list of strings containing the math expressions of the points visited by `f`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4e919-d8b2-4e1b-949e-3d0c45e9f754",
   "metadata": {},
   "source": [
    "The default solver in CVXPY often produces a __dense__ $\\lambda$ matrix. The number of dual variables $\\lambda_{ij}$ grows quadratically with the number of iterations $N$, making it impractical to infer a symbolic expression for $\\lambda$ when $N$ is large.\n",
    "\n",
    "However, the dual solution is not necessarily unique, and among all possible solutions, it is often desirable for $\\lambda$ to be __sparse__.\n",
    "Recall from ($\\blacksquare$) that each $\\lambda_{ij}$ the __weight__ assigned to the corresponding functional constraint associated with the pair $(x_i, x_j)$.\n",
    "When $\\lambda_{ij}=0$, the corresponding functional constraint is __inactive__: it does not contribute to the final convergence bound and can therefore be removed it from Primal PEP, yielding a __relaxation__.\n",
    "\n",
    "In practice, a sparse $\\lambda$ is often associated with elegant analytical proofs, which rely on just a few key inequalities rather than lengthy algebraic combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03d59f-8749-4025-9bd3-88a80aca5e9c",
   "metadata": {},
   "source": [
    "### Exploring relaxations of Primal PEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da825163-d168-4fa8-8b6d-3e4f0129529c",
   "metadata": {},
   "source": [
    "In <span class=\"brand-color\">PEPFlow</span>, sparse $\\lambda$ can be explored in an interactive manner.\n",
    "In the following dashboard, users can click entries in the left matrix to set the corresponding $\\lambda_{ij}$ to zero and observe the resulting changes in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53abca2d-f8b8-43cb-b3c5-bd4a676f0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pf.launch_primal_interactive(pep_builder, ctx, resolve_parameters={\"L\": sp.S(1), \"R\": sp.S(1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e4d13",
   "metadata": {},
   "source": [
    "This above line of code launches an interactive visualization of the $\\lambda$ matrix in a separate window.\n",
    "(A static image is shown here instead to ensure the website's availability.)\n",
    "\n",
    "\n",
    "![dashboard-1](../_static/dashboard-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb3093",
   "metadata": {},
   "source": [
    "Through a few rounds of trial and error, one can identify the following sparsity pattern for $\\lambda$.\n",
    "\n",
    "![dashboard-1](../_static/dashboard-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a102a8-4b4b-43c6-a161-d29021a563a0",
   "metadata": {},
   "source": [
    "With the sparsity pattern explored on the dashboard, we can solve the _relaxed_ Primal PEP and obtain the numerical primal and dual solutions. We first write a helper function that takes in the tag of an iterate and returns the index. For example, given `x_2` it will return the index `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "180768a3-b513-4f65-99a4-8fb9b011965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_to_index(tag, N=N):\n",
    "    \"\"\"\n",
    "    This is a function that takes in a tag of an iterate and returns its index.\n",
    "    We index \"x_star\" as \"x_{N+1} where N is the last iterate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the string on \"_\" and get the index\n",
    "    if (idx := tag.split(\"_\")[1]).isdigit():\n",
    "        return int(idx)\n",
    "    elif idx == \"star\":\n",
    "        return N + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0705d-d188-4fd2-bfc3-730df986fac3",
   "metadata": {},
   "source": [
    "The name of the interpolation constraints for the $L$-smooth convex function `f` is automatically generated by <span class=\"brand-color\">PEPFlow</span> and are of the form `f:x_i,x_j`. Based on the sparsity pattern explored on the dashboard, we can remove all the constraints except those of the form `f:x_{i},x_{i+1}` and `f:x_{i},x_{star}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb9ed97d-bdb0-4f25-928f-52e33d716c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxed_constraints = []\n",
    "\n",
    "for tag_i in lamb_dense.row_names:\n",
    "    i = tag_to_index(tag_i)\n",
    "    if i == N + 1:\n",
    "        continue\n",
    "    for tag_j in lamb_dense.col_names:\n",
    "        j = tag_to_index(tag_j)\n",
    "        if i < N and i + 1 == j:\n",
    "            continue\n",
    "        relaxed_constraints.append(f\"f:{tag_i},{tag_j}\")\n",
    "\n",
    "pep_builder.set_relaxed_constraints(relaxed_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc7892-f85f-4633-b4da-e5ef1ea0dab1",
   "metadata": {},
   "source": [
    "We now resolve the relaxed Primal PEP and store the information from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d603d42-5459-4e5f-9a33-de89afecea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pep_builder.solve(resolve_parameters={\"L\": sp.S(1), \"R\": sp.S(1)})\n",
    "\n",
    "# Dual variable associated with the initial condition\n",
    "tau_sol = result.dual_var_manager.dual_value(\"initial_condition\")\n",
    "\n",
    "# Dual variable associated with the interpolations conditions of f\n",
    "lamb_sol = result.get_scalar_constraint_dual_value_in_numpy(f)\n",
    "\n",
    "# Dual variable associated with the Gram matrix G\n",
    "S_sol = result.get_gram_dual_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a50851",
   "metadata": {},
   "source": [
    "```{admonition} Return type of result.get_gram_dual_matrix()\n",
    ":class: dropdown pepflow-dropdown\n",
    "\n",
    "The code line `get_gram_dual_matrix()` returns a `MatrixWithNames` object with the three member variables:\n",
    "- `matrix`: A `np.ndarray` containing the matrix dual variable associated with the gram matrix $G$;\n",
    "- `row_names`: A list of strings containing the math expressions of the basis points;\n",
    "- `col_names`: A list of strings containing the math expressions of the basis points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262ba96",
   "metadata": {},
   "source": [
    "### Find and verify symbolic expression of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46e4ef",
   "metadata": {},
   "source": [
    "From the numerical values, we tend to consider the following candidates for the closed form expression of $\\lambda$:\n",
    "\n",
    "```{math}\n",
    "\\lambda_{i-1,i} = \\frac{i}{2N+1-i}, \\;\\; i=1,\\ldots,N, \\qquad \\quad \\lambda_{\\star, i} = \\begin{cases}\n",
    "    \\lambda_{0,1} & i=0 \\\\\n",
    "    \\lambda_{i,i+1} - \\lambda_{i-1,i} \\quad & i=1,\\ldots,N-1 \\\\\n",
    "    1 - \\lambda_{i-1,i} & i=N,\n",
    "\\end{cases}\n",
    "```\n",
    "and other $\\lambda_{ij}$'s are zero.\n",
    "\n",
    "This candidate for $\\lambda$ is implemented in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a2a7ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|cccc}\n",
       "         & x_0 & x_1 & x_2 & x_\\star \\\\\n",
       "        \\hline\n",
       "        x_0 & 0.0 & 0.25 & 0.0 & 0.0 \\\\x_1 & 0.0 & 0.0 & 0.667 & 0.0 \\\\x_2 & 0.0 & 0.0 & 0.0 & 0.0 \\\\x_\\star & 0.25 & 0.417 & 0.333 & 0.0 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lamb(tag_i, tag_j, N=N):\n",
    "    i = tag_to_index(tag_i)\n",
    "    j = tag_to_index(tag_j)\n",
    "    if i == N + 1:  # Additional constraint 1 (between x_â˜…)\n",
    "        if j == 0:\n",
    "            return lamb(\"x_0\", \"x_1\")\n",
    "        elif j < N:\n",
    "            return lamb(f\"x_{j}\", f\"x_{j + 1}\") - lamb(f\"x_{j - 1}\", f\"x_{j}\")\n",
    "        elif j == N:\n",
    "            return 1 - lamb(f\"x_{N - 1}\", f\"x_{N}\")\n",
    "    if i < N and i + 1 == j:  # Additional constraint 2 (consecutive)\n",
    "        return j / (2 * N + 1 - j)\n",
    "    return 0\n",
    "\n",
    "\n",
    "lamb_cand = pf.pprint_labeled_matrix(\n",
    "    lamb, lamb_sol.row_names, lamb_sol.col_names, return_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeeb61c",
   "metadata": {},
   "source": [
    "We can check numerically whether our candidate of $\\lambda$ matches with the output solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fae565bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did we guess the correct symbolic expression of lambda? True\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Did we guess the correct symbolic expression of lambda?\",\n",
    "    np.allclose(lamb_cand, lamb_sol.matrix, atol=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8c674",
   "metadata": {},
   "source": [
    "We can also guess and verify the symbolic expression of $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff452065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did we guess the correct symbolic expression of tau? True\n"
     ]
    }
   ],
   "source": [
    "tau_cand = L / sp.S(4 * N + 2)\n",
    "\n",
    "print(\n",
    "    \"Did we guess the correct symbolic expression of tau?\",\n",
    "    np.allclose(pm.eval_scalar(tau_cand), tau_sol, atol=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f3b0a",
   "metadata": {},
   "source": [
    "## Step 2 SOS verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184ec6f",
   "metadata": {},
   "source": [
    "After we find and verify the symbolic expression for $\\lambda$, the remaining task is to verify the other dual variable, $S$, is positive semidefinite.\n",
    "We can visualize the numerical value of $S$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67653436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|ccccc}\n",
       "         & x_\\star & x_0 & \\nabla f(x_0) & \\nabla f(x_1) & \\nabla f(x_2) \\\\\n",
       "        \\hline\n",
       "        x_\\star & 0.1 & -0.1 & 0.125 & 0.208 & 0.167 \\\\x_0 & -0.1 & 0.1 & -0.125 & -0.208 & -0.167 \\\\\\nabla f(x_0) & 0.125 & -0.125 & 0.25 & 0.208 & 0.167 \\\\\\nabla f(x_1) & 0.208 & -0.208 & 0.208 & 0.667 & 0.167 \\\\\\nabla f(x_2) & 0.167 & -0.167 & 0.167 & 0.167 & 0.5 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "S_sol.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20259f1",
   "metadata": {},
   "source": [
    "With the basis system, we can easily extract the entry of $S$ corresponding to any entry of the Gram matrix $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cafc076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_star', 'x_0', 'grad_f(x_0)', 'grad_f(x_1)', 'grad_f(x_2)']\n",
      "['x_star', 'x_0', 'grad_f(x_0)', 'grad_f(x_1)', 'grad_f(x_2)']\n",
      "-0.2083265357493655\n"
     ]
    }
   ],
   "source": [
    "print(S_sol.row_names)\n",
    "print(S_sol.col_names)\n",
    "print(S_sol(\"grad_f(x_1)\", \"x_0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e757e",
   "metadata": {},
   "source": [
    "The numerical values may look complicated.\n",
    "But we already have its symbolic expression, from dual feasibility,\n",
    "\n",
    "```{math}\n",
    ":label: eq:S\n",
    "S = - C^\\text{PM} + \\tau C^\\text{IC} + \\sum\\limits_{(i,j) \\in \\mathcal{K}^\\star_N} \\lambda_{ij} C^\\text{FC}_{ij}.\n",
    "```\n",
    "All we need to verify is that $S$ is PSD, or equivalently, that $\\langle G, S \\rangle$ is nonnegative.\n",
    "Many approaches exist for this task; see, _e.g._,~[^1].\n",
    "One convenient way is to decompose $\\langle G, S \\rangle$ into a sum of squares.\n",
    "This approach is motivated by the fact that\n",
    "\n",
    "$$\n",
    "\\langle G, S \\rangle = \\langle H^TH, LL^T \\rangle = \\|HL\\|_F^2 = \\sum_j \\Big\\|\\sum_i L_{ij} h_i\\Big\\|^2,\n",
    "$$\n",
    "where $h_i$ is the $i$th column of $H$ and $S = LL^T$ is the Cholesky factorization.\n",
    "\n",
    "In our 2-step GD example, $H = \\begin{bmatrix} x_\\star & x_0 & g_0 & g_1 & g_2 \\end{bmatrix}$, and so\n",
    "\n",
    "```{math}\n",
    ":label: eq:S-prf-1\n",
    "\\begin{align*}\n",
    "\\langle G, S \\rangle = \\|HL\\|_F^2 &= \\|L_{11} x_\\star + L_{21} x_0 + L_{31} g_0 + L_{41} g_1 + L_{51} g_2\\|^2 \\\\\n",
    "&\\phantom{=} + \\|L_{22} x_0 + L_{32} g_0 + L_{42} g_1 + L_{52} g_2\\|^2 \\\\\n",
    "&\\phantom{=} \\;\\ \\vdots \\\\\n",
    "&\\phantom{=} + \\|L_{55} g_2\\|^2.\n",
    "\\end{align*}\n",
    "```\n",
    "\n",
    "On the other hand, we see from the definition of trace that\n",
    "\n",
    "```{math}\n",
    ":label: eq:S-prf-2\n",
    "\\begin{align*}\n",
    "\\langle G, S \\rangle &= \\left\\langle \\begin{bmatrix}\n",
    "    \\langle x_\\star, x_\\star \\rangle & \\langle x_\\star, x_0 \\rangle & \\langle x_\\star, g_0 \\rangle & \\langle x_\\star, g_1 \\rangle & \\langle x_\\star, g_2 \\rangle \\\\\n",
    "    \\langle x_0, x_\\star \\rangle & \\ast & \\ast & \\ast & \\ast \\\\\n",
    "    \\langle g_0, x_\\star \\rangle & \\ast & \\ast & \\ast & \\ast \\\\\n",
    "    \\langle g_0, x_\\star \\rangle & \\ast & \\ast & \\ast & \\ast \\\\\n",
    "    \\langle g_2, x_\\star \\rangle & \\ast & \\ast & \\ast & \\ast\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "    S_{11} & S_{21} & S_{31} & S_{41} & S_{51} \\\\\n",
    "    S_{21} & \\ast & \\ast & \\ast & \\ast \\\\\n",
    "    S_{31} & \\ast & \\ast & \\ast & \\ast \\\\\n",
    "    S_{41} & \\ast & \\ast & \\ast & \\ast \\\\\n",
    "    S_{51} & \\ast & \\ast & \\ast & \\ast\n",
    "\\end{bmatrix} \\right\\rangle \\\\[2pt]\n",
    "&= \\sum_{i,j} G_{ij} S_{ij} = S_{11} \\|x_\\star\\|^2 + 2\\langle x_\\star, S_{21} x_0 + S_{31} g_0 + S_{41} g_1 + S_{51} g_2 \\rangle + \\cdots.\n",
    "\\end{align*}\n",
    "```\n",
    "\n",
    "A key insight is that on the right-hand side of {eq}`eq:S-prf-1`, the only term that involves $x_\\star$ is $\\|L_{11} x_\\star + L_{21} x_0 + L_{31} g_0 + L_{41} g_1 + L_{51} g_2\\|^2$.\n",
    "Combining with {eq}`eq:S-prf-2`, we must have\n",
    "\n",
    "```{math}\n",
    "L_{11} = \\sqrt{S_{11}}, \\qquad L_{2:5,1} = \\frac{1}{L_{11}} S_{2:5,1},\n",
    "```\n",
    "\n",
    "which is exactly the first iteration of the Cholesky factorization algorithm.\n",
    "\n",
    "Moreover, the symbolic expression of the first column of $S$ can be extracted in a straightforward manner. \n",
    "We examine the three terms that define $S$ in {eq}`eq:S` one by one:\n",
    "\n",
    "- The first term, $C^\\text{PM}$, is zero because $G$ does not appear in the objective.\n",
    "- The second term, $C^\\text{IC}$, satisfies $\\langle G, C^\\text{IC} \\rangle = \\|x_\\star - x_0\\|^2$; thus, the contribution $\\tau C^\\text{IC}$ corresponds to $\\tau \\|x_\\star - x_0\\|^2$.\n",
    "- The terms $C^\\text{FC}_{ij}$ in the last summation correspond to the inner products $\\langle x_\\star, \\cdot \\rangle$ appearing in the functional constraints\n",
    "$f_j - f_i + \\langle g_j, x_i - x_j \\rangle + \\tfrac{1}{L} \\|g_i - g_j\\|^2 \\leq 0$.\n",
    "By inspecting the sparsity pattern of $\\lambda$, we observe that $\\lambda_{\\star, i}$ is nonzero for all $i=0,1,\\ldots,N$ and $\\lambda_{j,\\star} = 0$ for all $j=0,1,\\ldots,N$.\n",
    "Consequently, the summation in $S$ {eq}`eq:S` correspond to the inner product between $x_\\star$ and $\\sum_{i=0}^N \\lambda_{\\star, i} g_i$.\n",
    "\n",
    "To conclude, the squared term in $\\langle G, S \\rangle$ that involves $x_\\star$ is\n",
    "\n",
    "$$\n",
    "\\tau \\Big\\|x_\\star - x_0 + \\frac{1}{2\\tau} \\sum_{i=0}^N \\lambda_{\\star, i} g_i \\Big\\|^2,\n",
    "$$\n",
    "while all remaining terms in $\\langle G, S \\rangle$ are independent of $x_\\star$.\n",
    "\n",
    "The following code constructs the squared term involving $x_\\star$ and subtracts it from $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2d932",
   "metadata": {},
   "source": [
    "We first collect a list of the points visited by the function `f` and store the optimal solution `x_star`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d04b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x_0, x_1, x_2, x_star]\n"
     ]
    }
   ],
   "source": [
    "x = ctx.tracked_point(f)\n",
    "print(x)\n",
    "x_star = ctx[\"x_star\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26adc0bf",
   "metadata": {},
   "source": [
    "Now we construct the squared term involving $x_\\star$ and subtracts it from $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e55bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|ccccc}\n",
       "         & x_\\star & x_0 & \\nabla f(x_0) & \\nabla f(x_1) & \\nabla f(x_2) \\\\\n",
       "        \\hline\n",
       "        x_\\star & 0.0 & -0.0 & -0.0 & -0.0 & 0.0 \\\\x_0 & -0.0 & 0.0 & 0.0 & 0.0 & -0.0 \\\\\\nabla f(x_0) & -0.0 & 0.0 & 0.094 & -0.052 & -0.042 \\\\\\nabla f(x_1) & -0.0 & 0.0 & -0.052 & 0.233 & -0.181 \\\\\\nabla f(x_2) & 0.0 & -0.0 & -0.042 & -0.181 & 0.222 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tau_cand = L / sp.S(4 * N + 2)\n",
    "\n",
    "grad_terms = sum(lamb(x_star.tag, x[i].tag) * f.grad(x[i]) for i in range(N + 1))\n",
    "z_N = x_star - x_0 + 1 / (2 * tau_cand) * grad_terms\n",
    "iter_diff_square = tau_cand * z_N**2\n",
    "\n",
    "remainder_1 = S_sol.matrix - pm.eval_scalar(iter_diff_square).inner_prod_coords\n",
    "pf.pprint_labeled_matrix(remainder_1, S_sol.row_names, S_sol.col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b62d8",
   "metadata": {},
   "source": [
    "As expected, the first column and row of $S$ vanish, since all terms involving $x_\\star$ have been absorbed into the vector $z$ defined above.\n",
    "Interestingly, the second column and row, corresponding to $x_0$, also vanish.\n",
    "This is not a coincidence: in the GD example, shifting the function $f$ by a constant does not affect the worst-case performance of gradient descent.\n",
    "Consequently, only the relative position between $x_0$ and $x_\\star$ matters, not their absolute locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c168b63",
   "metadata": {},
   "source": [
    "We then follow the same process and eliminate the remaining <span class=\"brand-color\">basic vectors</span> $g_0,g_1,\\ldots,g_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb4fe9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|ccccc}\n",
       "         & x_\\star & x_0 & \\nabla f(x_0) & \\nabla f(x_1) & \\nabla f(x_2) \\\\\n",
       "        \\hline\n",
       "        x_\\star & 0.0 & -0.0 & -0.0 & -0.0 & 0.0 \\\\x_0 & -0.0 & 0.0 & 0.0 & 0.0 & -0.0 \\\\\\nabla f(x_0) & -0.0 & 0.0 & -0.0 & -0.0 & 0.0 \\\\\\nabla f(x_1) & -0.0 & 0.0 & -0.0 & -0.0 & 0.0 \\\\\\nabla f(x_2) & 0.0 & -0.0 & 0.0 & 0.0 & -0.0 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grad_diff_square = pf.Scalar.zero()\n",
    "for i in range(N + 1):\n",
    "    for j in range(i + 1, N + 1):\n",
    "        const_1 = (2 * N + 1) * lamb(x_star.tag, x[i].tag) - 1\n",
    "        const_2 = lamb(x_star.tag, x[j].tag)\n",
    "        grad_diff_square += (\n",
    "            1 / (2 * L) * (const_1 * const_2 * (f.grad(x[i]) - f.grad(x[j])) ** 2)\n",
    "        )\n",
    "\n",
    "remainder_2 = remainder_1 - pm.eval_scalar(grad_diff_square).inner_prod_coords\n",
    "pf.pprint_labeled_matrix(remainder_2, S_sol.row_names, S_sol.col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5c88d",
   "metadata": {},
   "source": [
    "We can easily verify our decomposition of $S$ as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9311e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did we guess the right closed form of S? True\n"
     ]
    }
   ],
   "source": [
    "S_guess = iter_diff_square + grad_diff_square\n",
    "\n",
    "print(\n",
    "    \"Did we guess the right closed form of S?\",\n",
    "    np.allclose(pm.eval_scalar(S_guess).inner_prod_coords, S_sol.matrix, atol=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd560939",
   "metadata": {},
   "source": [
    "## Symbolic calculation\n",
    "\n",
    "We can double check the proof identity\n",
    "\n",
    "$$\n",
    "    f_N - f_\\star - \\tau \\| x_0 - x_\\star \\|^2_2 = \\sum\\limits_{(i,j) \\in {\\mathcal K}^\\star_N} {\\lambda}_{ij} \\Big(f_j - f_i + \\langle g_j, x_i - x_j \\rangle + \\tfrac{1}{2L} \\| g_i - g_j \\|^2_2 \\Big) - \\langle G, S \\rangle\n",
    "$$\n",
    "\n",
    "using the symbolic computation system in `Sympy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26f995",
   "metadata": {},
   "source": [
    "We first assemble the summation term on RHS:\n",
    "\n",
    "$$\n",
    "\\sum\\limits_{(i,j) \\in {\\mathcal K}^\\star_N} {\\lambda}_{ij} \\Big(f_j - f_i + \\langle g_j, x_i - x_j \\rangle + \\tfrac{1}{2L} \\| g_i - g_j \\|^2_2 \\Big).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eff8d12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0+1/4*(f(x_1)-f(x_0)+\\nabla f(x_1)*(x_0-(x_1))+1/2*L*\\|\\nabla f(x_0)-\\nabla f(x_1)\\|^2)+2/3*(f(x_2)-f(x_1)+\\nabla f(x_2)*(x_1-(x_2))+1/2*L*\\|\\nabla f(x_1)-\\nabla f(x_2)\\|^2)+1/4*(f(x_0)-f(x_\\star)+\\nabla f(x_0)*(x_\\star-x_0)+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_0)\\|^2)+5/12*(f(x_1)-f(x_\\star)+\\nabla f(x_1)*(x_\\star-(x_1))+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_1)\\|^2)+1/3*(f(x_2)-f(x_\\star)+\\nabla f(x_2)*(x_\\star-(x_2))+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_2)\\|^2)$"
      ],
      "text/plain": [
       "0+1/4*(f(x_1)-f(x_0)+grad_f(x_1)*(x_0-(x_1))+1/2*L*|grad_f(x_0)-grad_f(x_1)|^2)+2/3*(f(x_2)-f(x_1)+grad_f(x_2)*(x_1-(x_2))+1/2*L*|grad_f(x_1)-grad_f(x_2)|^2)+1/4*(f(x_0)-f(x_star)+grad_f(x_0)*(x_star-x_0)+1/2*L*|grad_f(x_star)-grad_f(x_0)|^2)+5/12*(f(x_1)-f(x_star)+grad_f(x_1)*(x_star-(x_1))+1/2*L*|grad_f(x_star)-grad_f(x_1)|^2)+1/3*(f(x_2)-f(x_star)+grad_f(x_2)*(x_star-(x_2))+1/2*L*|grad_f(x_star)-grad_f(x_2)|^2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp_scalar_sum = pf.Scalar.zero()\n",
    "for x_i, x_j in itertools.product(x, x):\n",
    "    if lamb(x_i.tag, x_j.tag) != 0:\n",
    "        interp_scalar_sum += lamb(x_i.tag, x_j.tag) * f.interp_ineq(x_i.tag, x_j.tag)\n",
    "\n",
    "display(interp_scalar_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f502b",
   "metadata": {},
   "source": [
    "Then we assemble the entire RHS\n",
    "\n",
    "$$\n",
    "\\sum\\limits_{(i,j) \\in {\\mathcal K}^\\star_N} {\\lambda}_{ij} \\Big(f_j - f_i + \\langle g_j, x_i - x_j \\rangle + \\tfrac{1}{2L} \\| g_i - g_j \\|^2_2 \\Big) - \\langle G, S \\rangle.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f6c6777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0+1/4*(f(x_1)-f(x_0)+\\nabla f(x_1)*(x_0-(x_1))+1/2*L*\\|\\nabla f(x_0)-\\nabla f(x_1)\\|^2)+2/3*(f(x_2)-f(x_1)+\\nabla f(x_2)*(x_1-(x_2))+1/2*L*\\|\\nabla f(x_1)-\\nabla f(x_2)\\|^2)+1/4*(f(x_0)-f(x_\\star)+\\nabla f(x_0)*(x_\\star-x_0)+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_0)\\|^2)+5/12*(f(x_1)-f(x_\\star)+\\nabla f(x_1)*(x_\\star-(x_1))+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_1)\\|^2)+1/3*(f(x_2)-f(x_\\star)+\\nabla f(x_2)*(x_\\star-(x_2))+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_2)\\|^2)-(L/10*\\|x_\\star-x_0+1/2*L/10*(1/4*\\nabla f(x_0)+5/12*\\nabla f(x_1)+1/3*\\nabla f(x_2))\\|^2+0+1/2*L*5/48*\\|\\nabla f(x_0)-\\nabla f(x_1)\\|^2+1/2*L*1/12*\\|\\nabla f(x_0)-\\nabla f(x_2)\\|^2+1/2*L*13/36*\\|\\nabla f(x_1)-\\nabla f(x_2)\\|^2)$"
      ],
      "text/plain": [
       "0+1/4*(f(x_1)-f(x_0)+grad_f(x_1)*(x_0-(x_1))+1/2*L*|grad_f(x_0)-grad_f(x_1)|^2)+2/3*(f(x_2)-f(x_1)+grad_f(x_2)*(x_1-(x_2))+1/2*L*|grad_f(x_1)-grad_f(x_2)|^2)+1/4*(f(x_0)-f(x_star)+grad_f(x_0)*(x_star-x_0)+1/2*L*|grad_f(x_star)-grad_f(x_0)|^2)+5/12*(f(x_1)-f(x_star)+grad_f(x_1)*(x_star-(x_1))+1/2*L*|grad_f(x_star)-grad_f(x_1)|^2)+1/3*(f(x_2)-f(x_star)+grad_f(x_2)*(x_star-(x_2))+1/2*L*|grad_f(x_star)-grad_f(x_2)|^2)-(L/10*|x_star-x_0+1/2*L/10*(1/4*grad_f(x_0)+5/12*grad_f(x_1)+1/3*grad_f(x_2))|^2+0+1/2*L*5/48*|grad_f(x_0)-grad_f(x_1)|^2+1/2*L*1/12*|grad_f(x_0)-grad_f(x_2)|^2+1/2*L*13/36*|grad_f(x_1)-grad_f(x_2)|^2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RHS = interp_scalar_sum - S_guess\n",
    "display(RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81805d",
   "metadata": {},
   "source": [
    "We assemble the LHS in the same manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "004ad30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle f(x_2)-f(x_\\star)-L/10*\\|x_0-x_\\star\\|^2$"
      ],
      "text/plain": [
       "f(x_2)-f(x_star)-L/10*|x_0-x_star|^2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LHS = f(x[N]) - f(x_star) - L / (4 * N + 2) * (x[0] - x_star) ** 2\n",
    "display(LHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519a4bc",
   "metadata": {},
   "source": [
    "We display the difference using `Sympy`'s symbolic computation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e180150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle f(x_2)-f(x_\\star)-L/10*\\|x_0-x_\\star\\|^2-(0+1/4*(f(x_1)-f(x_0)+\\nabla f(x_1)*(x_0-(x_1))+1/2*L*\\|\\nabla f(x_0)-\\nabla f(x_1)\\|^2)+2/3*(f(x_2)-f(x_1)+\\nabla f(x_2)*(x_1-(x_2))+1/2*L*\\|\\nabla f(x_1)-\\nabla f(x_2)\\|^2)+1/4*(f(x_0)-f(x_\\star)+\\nabla f(x_0)*(x_\\star-x_0)+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_0)\\|^2)+5/12*(f(x_1)-f(x_\\star)+\\nabla f(x_1)*(x_\\star-(x_1))+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_1)\\|^2)+1/3*(f(x_2)-f(x_\\star)+\\nabla f(x_2)*(x_\\star-(x_2))+1/2*L*\\|\\nabla f(x_\\star)-\\nabla f(x_2)\\|^2)-(L/10*\\|x_\\star-x_0+1/2*L/10*(1/4*\\nabla f(x_0)+5/12*\\nabla f(x_1)+1/3*\\nabla f(x_2))\\|^2+0+1/2*L*5/48*\\|\\nabla f(x_0)-\\nabla f(x_1)\\|^2+1/2*L*1/12*\\|\\nabla f(x_0)-\\nabla f(x_2)\\|^2+1/2*L*13/36*\\|\\nabla f(x_1)-\\nabla f(x_2)\\|^2))$"
      ],
      "text/plain": [
       "f(x_2)-f(x_star)-L/10*|x_0-x_star|^2-(0+1/4*(f(x_1)-f(x_0)+grad_f(x_1)*(x_0-(x_1))+1/2*L*|grad_f(x_0)-grad_f(x_1)|^2)+2/3*(f(x_2)-f(x_1)+grad_f(x_2)*(x_1-(x_2))+1/2*L*|grad_f(x_1)-grad_f(x_2)|^2)+1/4*(f(x_0)-f(x_star)+grad_f(x_0)*(x_star-x_0)+1/2*L*|grad_f(x_star)-grad_f(x_0)|^2)+5/12*(f(x_1)-f(x_star)+grad_f(x_1)*(x_star-(x_1))+1/2*L*|grad_f(x_star)-grad_f(x_1)|^2)+1/3*(f(x_2)-f(x_star)+grad_f(x_2)*(x_star-(x_2))+1/2*L*|grad_f(x_star)-grad_f(x_2)|^2)-(L/10*|x_star-x_0+1/2*L/10*(1/4*grad_f(x_0)+5/12*grad_f(x_1)+1/3*grad_f(x_2))|^2+0+1/2*L*5/48*|grad_f(x_0)-grad_f(x_1)|^2+1/2*L*1/12*|grad_f(x_0)-grad_f(x_2)|^2+1/2*L*13/36*|grad_f(x_1)-grad_f(x_2)|^2))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff = LHS - RHS\n",
    "display(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c37db",
   "metadata": {},
   "source": [
    "With our basis system, we can easily simplify the above expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16bda8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle 0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf.pprint_str(\n",
    "    diff.repr_by_basis(ctx, sympy_mode=True, resolve_parameters={\"L\": sp.S(\"L\")})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d6c27",
   "metadata": {},
   "source": [
    "We can also verify that the coordinates of the LHS and the RHS match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d84d0270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{cccc}\n",
       "        f(x_\\star) & f(x_0) & f(x_1) & f(x_2) \\\\\n",
       "        \\hline\n",
       "        -1.0 & 0.0 & 0.0 & 1.0\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{cccc}\n",
       "        f(x_\\star) & f(x_0) & f(x_1) & f(x_2) \\\\\n",
       "        \\hline\n",
       "        -1.0 & 0.0 & 0.0 & 1.0\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RHS_func = pm.eval_scalar(RHS).func_coords\n",
    "pf.pprint_labeled_vector(RHS_func, ctx.basis_scalars_math_exprs())\n",
    "\n",
    "LHS_func = pm.eval_scalar(LHS).func_coords\n",
    "pf.pprint_labeled_vector(LHS_func, ctx.basis_scalars_math_exprs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb43578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|ccccc}\n",
       "         & x_\\star & x_0 & \\nabla f(x_0) & \\nabla f(x_1) & \\nabla f(x_2) \\\\\n",
       "        \\hline\n",
       "        x_\\star & -0.1 & 0.1 & 0.0 & -0.0 & 0.0 \\\\x_0 & 0.1 & -0.1 & 0.0 & 0.0 & 0.0 \\\\\\nabla f(x_0) & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\\nabla f(x_1) & -0.0 & 0.0 & 0.0 & -0.0 & -0.0 \\\\\\nabla f(x_2) & 0.0 & 0.0 & 0.0 & -0.0 & 0.0 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\displaystyle \n",
       "        \\begin{array}{c|ccccc}\n",
       "         & x_\\star & x_0 & \\nabla f(x_0) & \\nabla f(x_1) & \\nabla f(x_2) \\\\\n",
       "        \\hline\n",
       "        x_\\star & -0.1 & 0.1 & 0.0 & 0.0 & 0.0 \\\\x_0 & 0.1 & -0.1 & 0.0 & 0.0 & 0.0 \\\\\\nabla f(x_0) & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\\nabla f(x_1) & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\\nabla f(x_2) & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
       "        \\end{array}\n",
       "        $"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RHS_ip = pm.eval_scalar(RHS).inner_prod_coords\n",
    "pf.pprint_labeled_matrix(RHS_ip, ctx.basis_vectors_math_exprs())\n",
    "\n",
    "LHS_ip = pm.eval_scalar(LHS).inner_prod_coords\n",
    "pf.pprint_labeled_matrix(LHS_ip, ctx.basis_vectors_math_exprs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf73f69",
   "metadata": {},
   "source": [
    "We have shown that with the guessed symbolic expression of $(\\lambda, \\tau, S)$, LHS of {eq}`eq:gd-prf` is equal to RHS for $N=2$.\n",
    "\n",
    "You can also try other values of $N$ to check that the $(\\lambda, \\tau, S)$ candidate continues to hold, before finalizing the formal proof for the general case.\n",
    "\n",
    "This completes the entire PEP workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b833cf-1c99-48dd-87c4-7d704f2b3f57",
   "metadata": {},
   "source": [
    "[^1]: Y. Drori and M. Teboulle. Performance of first-order methods for smooth convex minimization: a novel approach. _Mathematical Programming_, 145(1-2):451â€“482, 2014.\n",
    "[^2]: A. B. Taylor, J. M. Hendrickx, and F. Glineur. Smooth strongly convex interpolation and exact worst-case performance of first-order methods. _Mathematical Programming_, 161(1-2):307â€“345, 2017.\n",
    "[^3]: B. Goujaud, A. Dieuleveut, and A. B. Taylor. On fundamental proof structures in first-order optimization. In _62nd IEEE Conference on Decision and Control (CDC)_, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pepflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
